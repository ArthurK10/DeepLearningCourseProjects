{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mmn11_Q2_DeepLearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIfPQNtdpyVK"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION A + B + C"
      ],
      "metadata": {
        "id": "PU7klUI2y3Tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def alt_expand(a,b):\n",
        "  #getting the shape of tensors A and B\n",
        "  a_dims = a.shape\n",
        "  b_dims = b.shape\n",
        "  offset = len(b_dims) - len(a_dims)\n",
        "\n",
        "  #making sure that tensor A is at least the size of tensor B\n",
        "  #also im scaning the tensors from the last element of shape, if both tensors have different dimensions at the same location\n",
        "  #and both diffrent than 1 then A can't be expanded and im returning an error\n",
        "  assert len(a_dims) <= len(b_dims) , print('Dimensions of tensor A are greater then tensor B, cant expand')\n",
        "  len_a, len_b = len(a_dims) - 1, len(b_dims) - 1\n",
        "  for i in range(len(a_dims)):\n",
        "    if ((a_dims[len_a]) != (b_dims[len_b])):\n",
        "      if((a_dims[len_a]) != 1) and ((b_dims[len_b]) != 1):\n",
        "        print(f'Cant expand')\n",
        "        return False\n",
        "    len_a -= 1\n",
        "    len_b -= 1\n",
        "  #cloning tensor A into ret_t (the tensor im returning)\n",
        "  ret_t = torch.clone(a)\n",
        "  #compering the dimensions of tensor A to the dimensions of thensor B, if dimensions of A are smaller then B we expand \n",
        "  #the dimensions of A to the dimensions of B\n",
        "  for i in range(len(a.shape)):\n",
        "    if a_dims[i] == b_dims[offset+i]: continue\n",
        "    lst = [ret_t] * b_dims[offset+i]\n",
        "    ret_t = torch.stack(lst, i+1)\n",
        "    ret_t = torch.squeeze(ret_t,i)\n",
        "  #here we expanding the size of tensor A to the size of tensor B\n",
        "  for i in reversed(range(offset)):\n",
        "      lst = [ret_t] * b_dims[i]\n",
        "      ret_t = torch.stack(lst, 0)\n",
        "\n",
        "\n",
        "  print(f'tensor a:\\n{a}', f'tensor b:\\n{b}', sep='\\n\\n')\n",
        "  print('\\n')\n",
        "  return ret_t\n"
      ],
      "metadata": {
        "id": "ylpKsa5wVCIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION B"
      ],
      "metadata": {
        "id": "iA8B1kcUCzrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_brod(a,b):\n",
        "  #getting the shape of tensors A and B\n",
        "  a_dims = a.shape\n",
        "  b_dims = b.shape\n",
        "  #making sure that tensor A is at leat the size of tensor B\n",
        "  #also im scaning the tensors from the last element of shape, if both tensors have different dimensions at the same location\n",
        "  #and both diffrent than 1 then A can't be expanded and im returning an error\n",
        "  assert len(a_dims) <= len(b_dims) , print('Dimensions of tensor A are greater then tensor B, cant expand')\n",
        "  len_a, len_b = len(a_dims) - 1, len(b_dims) - 1\n",
        "  for i in range(len(a_dims)):\n",
        "    if ((a_dims[len_a]) != (b_dims[len_b])):\n",
        "      if((a_dims[len_a]) != 1) and ((b_dims[len_b]) != 1):\n",
        "        return False\n",
        "    len_a -= 1\n",
        "    len_b -= 1\n",
        "  return True"
      ],
      "metadata": {
        "id": "ca_slP7rwgPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION C"
      ],
      "metadata": {
        "id": "9gJ5djNpjYH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def alt_brod_tensors(a,b):\n",
        "\n",
        "  #checking if tensors a and be can be broadcasted\n",
        "  ok_for_broad = is_brod(a,b)\n",
        "  if not ok_for_broad:\n",
        "    print('Cant broadcast this tensors')\n",
        "\n",
        "  #the size to wichw the tensors wil be broadcasted\n",
        "  new_size = list()\n",
        "\n",
        "  #order the tensors in ascending order by number of dimensions\n",
        "  if len(a.shape) <= len(b.shape):\n",
        "    up_a, up_b = a, b\n",
        "  else:\n",
        "    up_a, up_b = b, a\n",
        "  shape_a, shape_b = up_a.shape, up_b.shape\n",
        "\n",
        "  #adding degenerate dimensions to a\n",
        "  l = len(shape_b) - len(shape_a)\n",
        "  for i in range(l):\n",
        "    a = torch.unsqueeze(a, 0)\n",
        "    shape_a = a.shape\n",
        "\n",
        "  for i in range(len(shape_a)):\n",
        "    if shape_a[i] >= shape_b[i]:\n",
        "      size_dim = shape_a[i]\n",
        "    else:\n",
        "      size_dim = shape_b[i]\n",
        "    new_size.append(size_dim)\n",
        "    \n",
        "  #add the current dimension and its size to our list.\n",
        "  print(f'this is new_size: {new_size})')\n",
        "  empty_tr = torch.empty(new_size)\n",
        "  ret1, ret2 = alt_expand(a,empty_tr), alt_expand(b, empty_tr)\n",
        "\n",
        "\n",
        "  return ret1, ret2 "
      ],
      "metadata": {
        "id": "g0azk6dDD5rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION D"
      ],
      "metadata": {
        "id": "Or3r1z0Hjbdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(2,1,3)\n",
        "b = torch.rand(4,1,2,1,3)"
      ],
      "metadata": {
        "id": "LAdJ2oAFiRZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_res = alt_expand(a,b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUyn4d2Pj8Hq",
        "outputId": "1cc0443d-c93e-46d0-e04f-00f3cbc1e5d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor a:\n",
            "tensor([[[0.5953, 0.7305, 0.6995]],\n",
            "\n",
            "        [[0.3436, 0.5737, 0.0349]]])\n",
            "\n",
            "tensor b:\n",
            "tensor([[[[[0.4503, 0.7900, 0.3997]],\n",
            "\n",
            "          [[0.0092, 0.4480, 0.7698]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[0.7214, 0.4173, 0.6268]],\n",
            "\n",
            "          [[0.6724, 0.2568, 0.9142]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[0.8481, 0.7549, 0.2262]],\n",
            "\n",
            "          [[0.1585, 0.4920, 0.1334]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[0.0735, 0.6655, 0.2987]],\n",
            "\n",
            "          [[0.7496, 0.8272, 0.9128]]]]])\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_res = a.expand_as(b)"
      ],
      "metadata": {
        "id": "G7QmjnLckWS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = torch.equal(my_res, pytorch_res)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDrr9xDIlEu9",
        "outputId": "b91e9ed3-4778-453f-f72a-b651d6a8d2d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.rand(3,1)\n",
        "d = torch.rand(2,1,3)"
      ],
      "metadata": {
        "id": "vQKLL_Wfo_FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my1, my2 = alt_brod_tensors(c, d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4453LpgKlRbv",
        "outputId": "d5440cd1-6a1f-4a0a-970f-670c28be5a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is new_size: [2, 3, 3])\n",
            "tensor a:\n",
            "tensor([[[0.6596],\n",
            "         [0.1479],\n",
            "         [0.3508]]])\n",
            "\n",
            "tensor b:\n",
            "tensor([[[4.5232e-37, 3.0810e-41, 7.0065e-44],\n",
            "         [7.0065e-44, 6.3058e-44, 6.7262e-44],\n",
            "         [7.2868e-44, 6.3058e-44, 6.7262e-44]],\n",
            "\n",
            "        [[7.7071e-44, 1.1771e-43, 7.0065e-44],\n",
            "         [6.7262e-44, 8.1275e-44, 6.8664e-44],\n",
            "         [7.8473e-44, 8.1275e-44, 7.1466e-44]]])\n",
            "\n",
            "\n",
            "tensor a:\n",
            "tensor([[[0.6294, 0.2331, 0.2753]],\n",
            "\n",
            "        [[0.1124, 0.3638, 0.6859]]])\n",
            "\n",
            "tensor b:\n",
            "tensor([[[4.5232e-37, 3.0810e-41, 7.0065e-44],\n",
            "         [7.0065e-44, 6.3058e-44, 6.7262e-44],\n",
            "         [7.2868e-44, 6.3058e-44, 6.7262e-44]],\n",
            "\n",
            "        [[7.7071e-44, 1.1771e-43, 7.0065e-44],\n",
            "         [6.7262e-44, 8.1275e-44, 6.8664e-44],\n",
            "         [7.8473e-44, 8.1275e-44, 7.1466e-44]]])\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pt1, pt2 = torch.broadcast_tensors(c, d)"
      ],
      "metadata": {
        "id": "4fN8A27Zoag0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = torch.equal(my1, pt1) and torch.equal(my2, pt2)"
      ],
      "metadata": {
        "id": "737BWRK7okFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK6qwb-5owKb",
        "outputId": "61527c61-b117-42f6-bc9c-6ebf078b5e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JDXsry_VoyP2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}